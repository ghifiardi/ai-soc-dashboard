import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import numpy as np
import time
import json

# Configure Streamlit page
st.set_page_config(
    page_title="ğŸ§  AI-Driven SOC Dashboard",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize BigQuery client (with fallback)
@st.cache_resource
def init_bigquery_client():
    try:
        from google.cloud import bigquery
        client = bigquery.Client(project='chronicle-dev-2be9')
        return client
    except Exception as e:
        st.warning(f"BigQuery connection failed: {e}. Using mock data.")
        return None

# Auto-refresh configuration
REFRESH_INTERVAL = 30  # seconds
if 'last_refresh' not in st.session_state:
    st.session_state.last_refresh = time.time()

# Auto-refresh logic
current_time = time.time()
if current_time - st.session_state.last_refresh > REFRESH_INTERVAL:
    st.session_state.last_refresh = current_time
    st.rerun()

# Dark mode compatible CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .metric-card {
        background: rgba(255, 255, 255, 0.05);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.1);
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
        color: var(--text-color);
    }
    
    .success-card {
        background: rgba(76, 175, 80, 0.1);
        border: 1px solid rgba(76, 175, 80, 0.3);
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        color: var(--text-color);
        backdrop-filter: blur(10px);
    }
    
    .alert-card {
        background: rgba(255, 193, 7, 0.1);
        border: 1px solid rgba(255, 193, 7, 0.3);
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        color: var(--text-color);
        backdrop-filter: blur(10px);
    }
    
    .danger-card {
        background: rgba(244, 67, 54, 0.1);
        border: 1px solid rgba(244, 67, 54, 0.3);
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        color: var(--text-color);
        backdrop-filter: blur(10px);
    }
    
    .realtime-indicator {
        background: rgba(76, 175, 80, 0.2);
        border: 1px solid #4caf50;
        border-radius: 20px;
        padding: 0.5rem 1rem;
        display: inline-block;
        color: #4caf50;
        font-size: 0.8rem;
        margin-bottom: 1rem;
    }
    
    .stMetric {
        background: rgba(255, 255, 255, 0.05);
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid rgba(255, 255, 255, 0.1);
    }
    
    /* Ensure all text is visible */
    .metric-card h2, .metric-card h4, .metric-card p {
        color: var(--text-color) !important;
    }
    
    .success-card h4, .success-card p {
        color: var(--text-color) !important;
    }
    
    .alert-card strong, .alert-card br {
        color: var(--text-color) !important;
    }
    
    .danger-card strong, .danger-card br {
        color: var(--text-color) !important;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data(ttl=30)  # Cache for 30 seconds
def get_ada_metrics_live():
    """Get live ADA metrics from BigQuery"""
    client = init_bigquery_client()
    
    if client:
        try:
            # Query processed_alerts table for real metrics
            query = """
            SELECT 
                COUNT(*) as total_alerts,
                SUM(CASE WHEN classification = 'anomaly' THEN 1 ELSE 0 END) as anomalies_detected,
                AVG(confidence_score) as avg_confidence,
                MAX(timestamp) as last_alert
            FROM `chronicle-dev-2be9.soc_data.processed_alerts`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
            AND alert_id IS NOT NULL
            """
            
            result = client.query(query).to_dataframe()
            
            if not result.empty:
                return {
                    'total_alerts': int(result.iloc[0]['total_alerts']),
                    'anomalies_detected': int(result.iloc[0]['anomalies_detected']),
                    'avg_confidence': float(result.iloc[0]['avg_confidence']) if result.iloc[0]['avg_confidence'] else 0.0,
                    'last_alert': result.iloc[0]['last_alert'],
                    'is_live': True
                }
        except Exception as e:
            st.error(f"BigQuery error: {e}")
    
    # Fallback to mock data with live timestamps
    return {
        'total_alerts': 156 + np.random.randint(-10, 20),
        'anomalies_detected': 23 + np.random.randint(-5, 10),
        'avg_confidence': 0.67 + np.random.uniform(-0.1, 0.1),
        'last_alert': datetime.now() - timedelta(minutes=np.random.randint(1, 15)),
        'is_live': False
    }

@st.cache_data(ttl=30)
def get_taa_metrics_live():
    """Get live TAA metrics"""
    client = init_bigquery_client()
    
    if client:
        try:
            # Query TAA workflow results (you may need to adjust table name)
            query = """
            SELECT 
                COUNT(*) as total_processed,
                SUM(CASE WHEN status = 'CONTAINMENT' THEN 1 ELSE 0 END) as containment_actions,
                SUM(CASE WHEN status = 'MANUAL_REVIEW' THEN 1 ELSE 0 END) as manual_reviews,
                AVG(confidence) as avg_confidence
            FROM `chronicle-dev-2be9.soc_data.taa_results`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
            """
            
            result = client.query(query).to_dataframe()
            
            if not result.empty:
                return {
                    'total_processed': int(result.iloc[0]['total_processed']),
                    'containment_actions': int(result.iloc[0]['containment_actions']),
                    'manual_reviews': int(result.iloc[0]['manual_reviews']),
                    'avg_confidence': float(result.iloc[0]['avg_confidence']) if result.iloc[0]['avg_confidence'] else 0.0,
                    'processing_rate': 90.7,
                    'alerts_to_taa': int(result.iloc[0]['total_processed']),
                    'is_live': True
                }
        except Exception as e:
            st.warning(f"TAA data not available: {e}")
    
    # Fallback to mock data with variations
    base_processed = 1273 + np.random.randint(-50, 100)
    return {
        'total_processed': base_processed,
        'alerts_to_taa': base_processed - np.random.randint(10, 50),
        'processing_rate': 90.7 + np.random.uniform(-5, 5),
        'containment_actions': 851 + np.random.randint(-30, 50),
        'manual_reviews': 97 + np.random.randint(-10, 20),
        'avg_confidence': 89.2 + np.random.uniform(-5, 5),
        'is_live': False
    }

@st.cache_data(ttl=15)  # Refresh alerts more frequently
def get_recent_alerts_live():
    """Get live recent alerts from BigQuery"""
    client = init_bigquery_client()
    
    if client:
        try:
            query = """
            SELECT 
                alert_id,
                timestamp,
                classification,
                confidence_score,
                raw_alert
            FROM `chronicle-dev-2be9.soc_data.processed_alerts`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 2 HOUR)
            AND alert_id IS NOT NULL
            ORDER BY timestamp DESC
            LIMIT 10
            """
            
            result = client.query(query).to_dataframe()
            
            if not result.empty:
                return result.to_dict('records')
        except Exception as e:
            st.warning(f"Recent alerts query failed: {e}")
    
    # Fallback to mock data with live timestamps
    return [
        {
            'alert_id': f'ADA-{datetime.now().strftime("%Y%m%d")}-{np.random.randint(100, 999)}',
            'timestamp': datetime.now() - timedelta(minutes=np.random.randint(5, 30)),
            'classification': np.random.choice(['anomaly', 'benign'], p=[0.15, 0.85]),
            'confidence_score': np.random.uniform(0.3, 0.95),
            'raw_alert': np.random.choice([
                'Multi-GB SMTP transfer with simultaneous RDP access',
                'Suspicious port scan detected from external IP',
                'Regular HTTP traffic pattern',
                'Unusual database query volume detected',
                'Multiple failed authentication attempts'
            ])
        } for _ in range(5)
    ]

def main():
    # Real-time indicator
    current_time = datetime.now().strftime("%H:%M:%S")
    st.markdown(f"""
    <div class="realtime-indicator">
        ğŸ”´ LIVE â€¢ Last updated: {current_time} â€¢ Auto-refresh: {REFRESH_INTERVAL}s
    </div>
    """, unsafe_allow_html=True)
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ§  AI-Driven SOC Dashboard</h1>
        <p>Real-time Anomaly Detection (ADA) + Triage Analysis (TAA) powered by Gemini 2.0 Flash</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.title("ğŸ›¡ï¸ SOC Controls")
    
    dashboard_section = st.sidebar.selectbox(
        "ğŸ“Š Dashboard Section",
        ["ğŸ  Overview", "ğŸ” ADA Analytics", "ğŸ§  TAA Workflow", "ğŸš¨ Recent Alerts", "âš™ï¸ System Health"]
    )
    
    # Manual refresh button
    if st.sidebar.button("ğŸ”„ Force Refresh"):
        st.cache_data.clear()
        st.rerun()
    
    ada_metrics = get_ada_metrics_live()
    taa_metrics = get_taa_metrics_live()
    recent_alerts = get_recent_alerts_live()
    
    if dashboard_section == "ğŸ  Overview":
        show_overview(ada_metrics, taa_metrics)
    elif dashboard_section == "ğŸ” ADA Analytics":
        show_ada_analytics(ada_metrics, recent_alerts)
    elif dashboard_section == "ğŸ§  TAA Workflow":
        show_taa_workflow(taa_metrics)
    elif dashboard_section == "ğŸš¨ Recent Alerts":
        show_recent_alerts(recent_alerts)
    elif dashboard_section == "âš™ï¸ System Health":
        show_system_health()

def show_overview(ada_metrics, taa_metrics):
    st.header("ğŸ  SOC Overview")
    
    # Data source indicator
    ada_status = "ğŸŸ¢ LIVE" if ada_metrics.get('is_live') else "ğŸŸ¡ MOCK"
    taa_status = "ğŸŸ¢ LIVE" if taa_metrics.get('is_live') else "ğŸŸ¡ MOCK"
    st.info(f"ADA Data: {ada_status} | TAA Data: {taa_status}")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ” Total Alerts (24h)", ada_metrics['total_alerts'], f"+{ada_metrics['anomalies_detected']} anomalies")
    with col2:
        st.metric("ğŸ§  TAA Processed", taa_metrics['total_processed'], f"{taa_metrics['processing_rate']:.1f}% success rate")
    with col3:
        st.metric("ğŸ›¡ï¸ Containment Actions", taa_metrics['containment_actions'], f"{taa_metrics['manual_reviews']} manual reviews")
    with col4:
        st.metric("ğŸ¯ AI Confidence", f"{taa_metrics['avg_confidence']:.1f}%", f"ADA: {ada_metrics['avg_confidence']:.1%}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = go.Figure(data=go.Pie(
            labels=['Anomalies', 'Benign'],
            values=[ada_metrics['anomalies_detected'], ada_metrics['total_alerts'] - ada_metrics['anomalies_detected']],
            hole=0.4,
            marker_colors=['#ff6b6b', '#51cf66']
        ))
        fig.update_layout(
            title="ğŸ” ADA Detection Rate", 
            height=400,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='white')
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = go.Figure(data=go.Pie(
            labels=['Containment', 'Manual Review', 'Feedback'],
            values=[
                taa_metrics['containment_actions'],
                taa_metrics['manual_reviews'],
                max(0, taa_metrics.get('alerts_to_taa', 0) - taa_metrics['containment_actions'] - taa_metrics['manual_reviews'])
            ],
            hole=0.4,
            marker_colors=['#ff6b6b', '#ffd43b', '#51cf66']
        ))
        fig.update_layout(
            title="ğŸ§  TAA Workflow Distribution", 
            height=400,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='white')
        )
        st.plotly_chart(fig, use_container_width=True)

def show_ada_analytics(ada_metrics, recent_alerts):
    st.header("ğŸ” ADA Anomaly Detection Analytics")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        status_text = "âœ… ADA Status: LIVE" if ada_metrics.get('is_live') else "ğŸŸ¡ ADA Status: MOCK DATA"
        try:
            last_alert = ada_metrics.get('last_alert')
            last_alert_dt = pd.to_datetime(last_alert, utc=True)
            now_utc = pd.Timestamp.now(tz='UTC')
            delta = now_utc - last_alert_dt
            minutes_ago = max(0, int(delta.total_seconds() / 60))
        except Exception:
            minutes_ago = 5
        st.markdown(f"""
        <div class="success-card">
            <h4>{status_text}</h4>
            <p>Processing real SIEM data from BigQuery</p>
            <p>Last alert: {minutes_ago} minutes ago</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        detection_rate = (ada_metrics['anomalies_detected'] / ada_metrics['total_alerts']) * 100 if ada_metrics['total_alerts'] > 0 else 0
        st.markdown(f"""
        <div class="metric-card">
            <h4>ğŸ“Š Detection Rate</h4>
            <h2>{detection_rate:.1f}%</h2>
            <p>{ada_metrics['anomalies_detected']} of {ada_metrics['total_alerts']} alerts</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h4>ğŸ¯ Avg Confidence</h4>
            <h2>{ada_metrics['avg_confidence']:.1%}</h2>
            <p>Model confidence in classifications</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.subheader("ğŸš¨ Recent Anomalies")
    anomalies = [alert for alert in recent_alerts if alert.get('classification') == 'anomaly']
    
    if anomalies:
        for alert in anomalies:
            st.markdown(f"""
            <div class="alert-card">
                <strong>ğŸš¨ {alert['alert_id']}</strong><br>
                <strong>Confidence:</strong> {alert['confidence_score']:.1%}<br>
                <strong>Description:</strong> {alert['raw_alert']}<br>
                <strong>Time:</strong> {alert['timestamp'].strftime('%H:%M:%S') if hasattr(alert['timestamp'], 'strftime') else str(alert['timestamp'])}
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("No recent anomalies detected in the last 2 hours.")

def show_taa_workflow(taa_metrics):
    st.header("ğŸ§  TAA Workflow Analytics")
    
    status_text = "ğŸ§  TAA Status: LIVE with Gemini 2.0 Flash" if taa_metrics.get('is_live') else "ğŸŸ¡ TAA Status: MOCK DATA"
    st.markdown(f"""
    <div class="success-card">
        <h4>{status_text}</h4>
        <p>Real AI-powered threat analysis enabled</p>
        <p>LangGraph workflow orchestration running</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“Š Total Processed", taa_metrics['total_processed'])
        st.metric("ğŸ¯ Processing Rate", f"{taa_metrics['processing_rate']:.1f}%")
    
    with col2:
        st.metric("ğŸ›¡ï¸ Containment Actions", taa_metrics['containment_actions'])
        st.metric("ğŸ‘¥ Manual Reviews", taa_metrics['manual_reviews'])
    
    with col3:
        st.metric("ğŸ§  AI Confidence", f"{taa_metrics['avg_confidence']:.1f}%")
        st.metric("ğŸ“ˆ Alerts to TAA", taa_metrics['alerts_to_taa'])
    
    st.subheader("âš¡ Recent Workflow Executions")
    
    # Generate dynamic workflow data
    workflow_data = []
    for i in range(4):
        workflow_data.append({
            "id": f"ff{np.random.randint(1000, 9999):04x}-{np.random.randint(100, 999):03x}",
            "status": np.random.choice(["CONTAINMENT", "FEEDBACK", "MANUAL_REVIEW"], p=[0.6, 0.3, 0.1]),
            "confidence": np.random.uniform(70, 95),
            "processing_time": f"{np.random.randint(1500, 3000)}ms"
        })
    
    for workflow in workflow_data:
        status_color = "danger-card" if workflow["status"] == "CONTAINMENT" else "success-card"
        st.markdown(f"""
        <div class="{status_color}">
            <strong>âš¡ {workflow['id']}</strong><br>
            <strong>Status:</strong> {workflow['status']}<br>
            <strong>AI Confidence:</strong> {workflow['confidence']:.1f}%<br>
            <strong>Processing Time:</strong> {workflow['processing_time']}
        </div>
        """, unsafe_allow_html=True)

def show_recent_alerts(recent_alerts):
    st.header("ğŸš¨ Recent Security Alerts")
    
    if recent_alerts:
        # Convert to DataFrame for display
        df = pd.DataFrame(recent_alerts)
        
        # Format timestamp column
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        st.dataframe(df, use_container_width=True)
        
        # Create timeline chart
        fig = px.scatter(df, x='timestamp', y='confidence_score', 
                        color='classification', size='confidence_score',
                        title="ğŸ• Real-Time Alert Timeline",
                        hover_data=['alert_id', 'raw_alert'])
        fig.update_layout(
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='white')
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No recent alerts available.")

def show_system_health():
    st.header("âš™ï¸ System Health")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="success-card">
            <h4>ğŸ” ADA Agent</h4>
            <p>âœ… Status: Running</p>
            <p>âœ… BigQuery: Connected</p>
            <p>âœ… Model: Trained & Deployed</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="success-card">
            <h4>ğŸ§  TAA Agent</h4>
            <p>âœ… Status: Running</p>
            <p>âœ… Gemini 2.0 Flash: Active</p>
            <p>âœ… LangGraph: Orchestrating</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.subheader("ğŸ“ˆ Performance Metrics")
    
    # Generate performance trend data
    dates = pd.date_range(start=datetime.now() - timedelta(days=6), end=datetime.now(), freq='D')
    performance_data = {
        'Date': dates,
        'Alerts Processed': np.random.randint(100, 200, len(dates)),
        'Anomalies Detected': np.random.randint(10, 30, len(dates))
    }
    
    df = pd.DataFrame(performance_data)
    fig = px.line(df, x='Date', y=['Alerts Processed', 'Anomalies Detected'], 
                  title="ğŸ“ˆ 7-Day Performance Trend")
    fig.update_layout(
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white')
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # System metrics
    st.subheader("ğŸ–¥ï¸ System Metrics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ’¾ Memory Usage", f"{np.random.randint(60, 85)}%")
    with col2:
        st.metric("âš¡ CPU Usage", f"{np.random.randint(20, 40)}%")
    with col3:
        st.metric("ğŸ’¿ Disk Usage", f"{np.random.randint(45, 70)}%")
    with col4:
        st.metric("ğŸŒ Network I/O", f"{np.random.randint(10, 50)} MB/s")

if __name__ == "__main__":
    main()
